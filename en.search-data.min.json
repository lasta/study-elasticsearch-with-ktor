[{"id":0,"href":"/study-elasticsearch-with-ktor/elasticsearch/","title":"Elasticsearch","parent":"Study Elasticsearch with Ktor","content":""},{"id":1,"href":"/study-elasticsearch-with-ktor/elasticsearch/textanalysis/","title":"テキスト解析","parent":"Elasticsearch","content":"wip\n"},{"id":2,"href":"/study-elasticsearch-with-ktor/elasticsearch/indexmodules/analysis/","title":"Analysis","parent":"Index modules","content":"Index analysis module は文字列フィールドを term に分割するための解析器の構成を登録するためのレジストリとして機能します。\n document を検索可能にするための転置インデックスを作成 検索 term を生成する match query のような高レベルのクエリで使用される  詳細は テキスト解析 の章を参照してください。\n"},{"id":3,"href":"/study-elasticsearch-with-ktor/elasticsearch/indexmodules/","title":"Index modules","parent":"Elasticsearch","content":"Index modules は index ごとに作成されるモジュールです。 index のあらゆる面を制御します。\nIndex の設定    Index level settings は index ごとに設定されます。\n static  Index の作成時または closed index に指定可能な静的な設定です。   dynamic  update-index-settings を用いて動的に変更可能な設定です。     注意\nclosed index の設定を変更すると、 index の削除および再作成が必要になる場合があります。\n 静的な設定項目 - Static index settings    index.number_of_shards    index が持つべき primary shard の数を設定します。 デフォルト値は1で、 index の作成時のみ設定可能です。 closed index では変更不可能です。\n Note\n1 index あたりの shard の数はデフォルトで 1024 個までに制限されています。 リソースの割当によってクラスタを不安定にする可能性のある index が誤って作成されるのを防ぐための安全上の制限です。\nすべてのノードで export ES_JAVA_OPTS=\u0026quot;-Des.index.max_number_of_shards=128\u0026quot; などのように指定することで変更可能です。\n index.number_of_routing_shards    Index の 分割 の際に用いられる、 routing shard の数を設定します。\n5 shards で number_of_routing_shards が 30 の場合、2倍または3倍に分割される可能性があります。\n 5 → 10 → 30 (2つに分けて、さらに3つに分ける) 5 → 15 → 30 (3つに分けて、さらに2つに分ける) 5 → 60 (6つに分ける)  この設定のデフォルト値は、 index の primary shards の数に依存します。 デフォルトでは最大 1024 個の shard まで 2 の係数で分割できるように設計されています。\n Note\nElasticsearch 7.0.0 以降では、この設定は shard 間でのドキュメントの分割方法に影響します。 カスタムルーティングを仕様した古い index を再 index する際、同じドキュメント配分を維持するためには、 index.number_of_routing_shards を 明示的に設定する必要があります。\n詳細は related breaking change を確認してください。\n index.shard.check_on_startup    起動時に shard の破損をチェックするかどうか指定します。 破損が検出された場合、 shard を参照することができなくなります。\n false  デフォルト値 shard を参照する際に破損しているかどうかチェックしない   checksum  物理的に破損しているかどうかチェックする   true  破損しているかどうか物理的にも論理的にもチェックする 非常に CPU とメモリを食う     注意\n熟練者向けの設定です。\nindex のサイズが大きい場合、 shard の破損の確認は時間がかかります。\n index.codec    デフォルトでは、保存されたデータは LZ4 で圧縮されます。 best_compression を指定することで、 DEFLATE を利用してより圧縮率になりますが、フィールド参照時のパフォーマンスが劣化します。\n圧縮の種類を変更した場合、セグメントが結合されたあとに新しい圧縮方式が適用されます。 セグメントの結合は force merge で強制的に行う事ができます。\nindex.routing_partition_size    カスタム ルーティング 時に値を送信できる shard の数を指定します。 デフォルト値は1です。 index 作成時のみ設定できます。\nこの値は index.number_of_shards の値が 1 でない限り、 index.number_of_shards の値より小さくなければなりません。 詳細は Routing to an index partition を参照してください。\nindex.soft_deletes.enabled     注意\nElasticsearch 7.6.0 で Deprecated になりました。 soft-deletes を無効にした index の作成が非推奨になりました。\n将来的にはこの設定項目が削除される予定です。\n index で soft-deletes を有効にするかどうか指定します。 soft-deletes は index 作成時のみ指定可能です。 Elasticsearch 6.5.0 以降で作成された index のみ設定できます。 デフォルト値は true です。\nindex.soft_deletes.retention_lease.period    shard history retention lease が期限切れとみなされるまでの最大保持期間を指定します。 shard history retention lease は、 lucene index のマージ時に soft-deletes されないよう保持します。 soft-deletes がレプリケーションされる前にマージされてしまうと、履歴が不完全な状態になるため、後続の処理が失敗します。\nデフォルト値は 12h (12 時間) です。\nindex.load_fixed_bitset_filters_eagerly    ネストされたクエリに対し、 cached filters を遅延読み込みするかどうか指定します。 デフォルト値は true で遅延読み込みしません。 (eager load) false で遅延読み込み (lazy load) します。\nindex.hidden    index をデフォルトで非表示にするかどうか指定します。 ワイルドカードで index を指定した場合、デフォルトでは非表示の index は返却されません。 リクエストごとに expand_wildcards パラメータにて正義よされます。\n指定できる値は true か false で、デフォルトでは false です。\n動的な設定項目 - Dynamic index settings    index.number_of_replicas    各 primary shard のレプリカ数を指定します。 デフォルト値は1です。\nindex.auto_expand_replicas    クラスタのデータノード数に応じて、レプリカ数を自動的に拡張するかどうかを指定します。\n false (既定値)  無効   ダッシュ区切りで指定 (例: 0-5)  下限と上限を設定   0-all  すべてを使用    自動拡張されたレプリカ数は allocation filtering ルールのみ考慮され、 ノードごとの合計シャード数 を始めとした他の割当規則が無視されることに注意してください。 適用可能なルールによってすべてのレプリカが割り当てられない場合、クラスタの滋養帯が YELLOW になる可能性があります。\n上限が all の場合、 shard allocation awareness および cluster.routing.allocation.same_shard.host は無視されます。\nindex.search.idle.after    shard idle 状態 (検索や get リクエストが来ていない) とみなすまでの時間を指定します。 デフォルト値は 30秒 (30s) です。\nindex.refresh_interval    index に対する直近の変更を検索に反映させるまでのリフレッシュを行う頻度を指定します。 デフォルト値は 1秒 (1s) です。 -1 を指定すると、リフレッシュが無効になります。\nこの設定が明示的に指定されていない場合、少なくとも index.search.idle.after で指定した時間検索トラフィックが来ていない shard は、 検索リクエストが来るまでバックグラウンドでリフレッシュしません。 リフレッシュされていない idle 状態の shard にヒットした場合、次のバックグラウンドでのリフレッシュを待ちます。 (1秒以内) この動作は、検索が行われない bulk indexing の動作を自動的に最適化することを目的としています。 これを無効にするには、明示的に 1s を指定する必要があります。\nindex.max_result_window    検索時の from + size の最大値を指定します。 デフォルト値は 10000 です。\nfrom + size に大きな値を指定するとメモリと時間を消費する (ディープページング問題) ための対策です。\nこの値を上げない効率的な方法については、 Scroll と Search After を参照してください。\nindex.max_inner_result_window    inner hits や top hits aggregations の際の from + size の上限値を指定します。 デフォルト値は 100 です。\ninner hits や top hits aggregations は from + size に比例してメモリと時間を消費します。\nindex.max_rescore_window    rescore の window_size の最大値を指定します。 デフォルト値は index.max_result_window です。\nmax(window_size, from + size) に比例してしてメモリと時間を消費します。\nindex.max_docvalue_fields_search    クエリで許容される docvalue_fields の最大値を指定します。 デフォルト値は 100 です。\nDoc-value フィールドは、各ドキュメントの各フィールドごとに seek が発生する場合があります。\nindex.max_script_fields    1クエリでの script_fields の個数の上限値を指定します。 デフォルト値は 32 です。\nindex.max_ngram_diff    NGramTokenizer や NGramTokenFilter における min_gram と max_gram 間の最大の差を指定します。 デフォルト値は1です。\nindex.max_shingle_diff    shingle token filter における max_shingle_size と min_shingle_size 間の最大の差を指定します。 デフォルト値は 3 です。\nindex_max_refresh_listeners    index の各 shard で利用可能な refresh listener の最大数を指定します。 この listener は refresh=wait_for で使用されます。\nindex.analyze.max_token_count    生成される token 数の最大値を指定します。 analyze API で使用されます。 デフォルト値は 10000 です。\nindex.highlight.max_analyzed_offset    highlight リクエストにて解析される文字の最大数を指定します。 この設定は、 offset または term vector なしで index されたテキストに対し highlight が要求された場合のみ適用されます。 デフォルト値は 1000000 です。\nindex.max_terms_count    Terms Query における terms 数の最大値を指定します。 デフォルト値は 65536 です。\nindex.max_regex_length    Regexp Query における正規表現の長さの上限を指定子ます。 デフォルト値は 1000 です。\nindex.query.default_field    デフォルトの検索対象のフィールドを指定します。 文字列または文字列の配列を指定できます。\nこのフィールドは下記クエリで利用されます。\n More like this Multi-match Query string Simple query string  デフォルト値は * です。 メタデータフィールドを除く、 term-level クエリの対象となるすべてのフィールドを対象とします。\nindex.routing.allocation.enable    shard の割当を制御します。\n all (デフォルト値)  すべての shard に対して shard allocation を許可する   primaries  primary shard のみ shard allocation を許可する   new_primaries  新たに作成された primary shard のみ shard allocation を許可する   none  shard allocation をしない    index.routing.rebalance.enable    shard の再バランシング (shard rebalancing) を有効化します。\n all (デフォルト値)  すべての shard   primaries  primary shard のみ   replicas  replica shard のみ   none  許可しない    index.gc_deletes    削除された document のバージョン番号 が その後のバージョン操作 によって再利用可能になるまでの時間を指定します。\nデフォルト値は 60秒 (60s) です。\nindex.default_pipeline    デフォルトの ingest node パイプラインを指定します。 デフォルトのパイプラインが設定されていて、かつそのパイプラインが存在しない場合、 index へのリクエストは失敗します。\npipeline パラメータを使用して上書きできます。\n特殊なパイプライン名 _none は、 ingest pipeline を実行しないことを示します。\ninex.final_pipeline    index の final ingest node パイプラインを指定します。 final pipeline が指定され、かつその pipeline が存在しない場合、 index へのリクエストは失敗します。\nfinal pipeline は、 request pipeline (指定されている場合) と default pipelin (存在する場合) のあとに常に実行されます。\n特殊な pipeline 名 _none は、 ingest pipeline が実行されないことを示します。\n他の index modules の設定     Analysis  解析器 (analyzers)、形態素解析器 (tokenizers)、トークンフィルタ (token filters)、キャラクタフィルタ (character filters) の設定   Index shard allocation  node に対し、いつどこにどうやって shard が配置されるかどうかの設定   Mapping  動的 mapping の有効 / 無効の設定   Merging  バックグラウンド実行される merge process によって shard がどうマージされるかどうかの設定   Similarities  検索結果のスコアリングのカスタマイズのための、類似度をカスタマイズするための設定   Slowlog  query と fetch の slow-log の設定   Store  shard データへアクセスする際のファイルシステムの種類の設定   Translog  トランザクションログとバックグラウンド実行される flush 処理の設定   History retention  index の操作履歴の設定   Indexing pressure  index データの圧縮に関する設定    "},{"id":4,"href":"/study-elasticsearch-with-ktor/elasticsearch/setup/configure/important/","title":"本番運用時の重要な設定","parent":"設定","content":"参照元ドキュメント : Important Elasticsearch configuration\nローカル等で使い始める分にはほとんどデフォルトの設定で問題ありません。 クラスタを本番運用するためには考慮すべき設定値を解説します。\nElastic Cloud を利用する場合は特に考慮不要です。\n   パスの設定 path.data の複数指定 クラスタ名 ノード名 ネットワークホスト ディスカバリとクラスタ形成  discovry.seed_hosts cluster.initial_master_nodes   ヒープサイズの設定 JVM のヒープダンプのパス GC ログの設定 例 tmp ファイルの設定 JVM fatal error ログ クラスタのバックアップ     パスの設定    Elasticsearch は index したデータとデータストリームを data ディレクトリ内に書き込みます。 クラスタの状態等のログは logs ディレクトリに書き込みます。\nMac や Linux 上に tar.gz を用いてインストール した場合、および Windows 上に .zip を用いてインストール した場合は、 data ディレクトリと logs ディレクトリは $ES_HOME 配下に配置されます。 ですが、この $ES_HOME ディレクトリは Elaticsearch のアップグレード時に削除される危険性があります。\n本番環境では、 elasticsearch.yml にて $ES_HOME 外に path.data と path.logs を設定することを強く推奨します。\nDocker 、 RPM 、 MacOS Homebrew 、 Windows .msi でインストールした場合は、 logs と data ディレクトリはデフォルトで $ES_HOME 外の場所に設定されています。\n 重要\nエラーを避けるために、 path.data ディレクトリ配下を参照するのは Elasticsearch だけにしてください。\nウィルス対策ソフトやバックアップシステムなど、ファイルを開いたりロックを取るようなサービスでは、 path.data ディレクトリを走査対象外に指定してください。\n Linux 系および MacOS での設定例です。\n1 2 3  path:data:/var/data/elasticsearchlogs:/var/log/elasticsearch  path.data の複数指定     注意\nElasticsearch 7.13.0 にて非推奨になりました。\n path.data に複数のパスを指定することができます。 Elasticsearch は指定されたすべてのパスにノードのデータを保存しますが、各シャードのデータは同じパスに保存します。\nElasticsearch はノードのデータのパス間で shard のバランシングをしません。 ある1つのパスでディスク使用量が多いと、「ノード全体のディスク使用量が多い」ステータス ([high disk usage watermark][Disk-based allocation settings]) になります。 この状態になると、他のパスのディスク容量に余裕があったとしても、そのノーシドに shard を追加できなくなります。 追加のディスク容量が必要な場合は、データのパスを追加するのではなく、ノードを追加することを推奨します。\nクラスタ名    同一クラスタ内のすべてのノードの cluster.name を揃える必要があります。 デフォルトの名前は elasticsearch ですが、クラスタの目的を説明する適切な名前に変更してください。\n1  cluster.name:logging-prod   重要\n異なる環境でクラスタ名を再利用しないでください。 ノードが想定外のクラスタに属してしまうかもしれません。\n ノード名    node.name に人間が理解できる識別子を指定します。\nこの名前は、多くの API のレスポンスに含まれます。 ノード名のデフォルト値は Elasticsearch 起動時のマシンのホスト名ですが、 elasticsearch.yml で明示的に設定することもできます。\n1  node.name:prod-data-2  ネットワークホスト    デフォルトでは、 127.0.0.1 や [::1] などのループバックアドレスのみバインドします。 開発やテストの際に1台のサーバで複数のノードからなるクラスタを構築する場合は問題ないですが、本番環境ではサーバは複数台構成にになります。 ネットワークの設定項目はたくさんありますが、多くの場合設定が必要となるのは network.host だけになります。\n1  network.host:192.168.1.10   注意\nnetwork.host に値を指定すると、 Elasticsearch は開発モードから本番モードへ移行しているとみなし、 システム起動時の殆どのチェック項目について失敗した際の警告レベルを warning から exception に昇格させます。\n詳細は 開発モードと本番モードの違い を確認してください。\n ディスカバリとクラスタ形成    本番環境に導入する前に、ディスカバリとクラスタ形成の設定を行ってください。\nクラスタ内のノードが互いを発見できるようになり、マスターノードを選出できるようになります。\ndiscovry.seed_hosts    ネットワークの設定を特に行わなくても、ローカルの 9300 〜 9305 番ポートをスキャンして、同じサーバ上で起動している他のノードに接続します。 この動作のおかげで、、特に設定をしなくても自動的にクラスタが作成されます。\n他のホスト上のノードとクラスタを形成したい場合は、静的に discovery.seed_hosts を設定します。 この設定により Master 候補 (master eligible node) であり生きていてコンタクト可能な、クラスタ内の他のノードの一覧を ディスバリプロセス のシードに提供されます。 クラスタ内にあるすべての Master 候補のノードのアドレスを、配列で定義します。 各アドレスは、最終的に DNS 等で解決できれば、ホスト名でも IP アドレスの直指定でも問題ありません。\n1 2 3 4 5  discovery.seed_hosts:- 192.168.1.10:9300- 192.168.11.1# 1.- seeds.mydomain.com # 2.- [0:0:0:0:0:ffff:c0a8:10c]:9301 # 3.   1.\nポート番号が指定されなかった場合は、デフォルト値の 9300 ポートになります。 (オーバーライド可能)\n  2.\nホスト名が複数の IP アドレスに解決された場合、解決されたすべての IP アドレスに有るノードをディスカバリしようとします。\n  3.\nIPv6 の場合、角括弧で囲まなければなりません\n Master 候補のノードが固定の名前やアドレスを持っていない場合は、 代替ホストプロバイダ を使用してアドレスを動的に検索できるようにします。\ncluster.initial_master_nodes    初めてクラスタを起動する際、 [cluster bootstrapping] ステップでは、最初の Master 選出選挙の候補となるノード群を決定します。 開発モード ではディスカバリ設定が構成されないため、ノード自身によって自動的に実行されます。\n自動的な bootstrap は 本質的には安全ではない ため、本番モードで新しいクラスタを起動する場合は、 Master 候補を cluster.initial_master_nodes に明示的に指定します。\n 重要\n初回のクラスタ構築に成功したあとは、各ノードから cluster.initial_master_nodes の設定を削除してください。 クラスタを再起動する際や新しいノードを追加する際には指定しないでください。\n 1 2 3 4 5 6 7 8 9  discovery.seed_hosts:- 192.168.1.10:9300- 192.168.1.11- seeds.mydomain.com- [0:0:0:0:0:ffff:c0a8:10c]:9301cluster.initial_master_nodes:- master-node-a- master-node-b- master-node-c  cluster.initial_master_nodes には Master 候補のノード名を指定します。 各ノードの node.name で指定した値を正確に指定してください。 デフォルトではホスト名になっています。\nたとえば、ノード名に master-node-a.example.com のような FQDN (Fully-qualified domain name; 完全修飾ドメイン名) を使用している場合は、 その FQDN を指定しなければなりません。 逆に、 node.name が末尾に修飾子を持たない生のホスト名の場合は、 cluster.initial_master_nodes では末尾の修飾子を省略しなければなりません。\nヒープサイズの設定    Elasticsearch は、ノードの役割とサーバのメモリ量に基づいて、 JVM のヒープサイズを自動的に設定します。 ほとんどの場合では、デフォルト状態のままにすることを推奨します。\n Note\nヒープサイズの自動調整は、バンドルされている JDK 、または Java 14 以降の JRE を利用している場合のみ有効になります。\n 別途調整が必要な場合は、手動で指定することができます。 settings the JVM heap size を参照してください。\nJVM のヒープダンプのパス    デフォルトでは、 OOME が発生した際にヒープダンプを作成します。 RPM および Debian 系では /var/lib/elasticsaerch 、 zip や tar.gz でインストールした場合は、 ES_ROOT に配置されます。\nパスを変更したい場合は、 jvm.options にある -XX:HeapDumpPath=... を修正してください。\n ディレクトリを指定した場合  ヒープダンプファイル名は PID に基づいて自動生成される   ファイル名を指定した場合  指定したパスにファイルが存在しない場合、そのパスにヒープダンプが生成される 指定したパスにファイルが存在する場合、ヒープダンプに失敗する    GC ログの設定    GC ログの出力はデフォルトで有効になっています。 jvm.options で設定可能です。 ログのデフォルトの出力先は Elasticsearch のログと同じ場所になります。 ログローテーションは 64MB ごとに行われ、合計で最大 2GB 消費します。\nJEP 158: Unified JVM Logging にあるコマンドラインオプションを用いて、ログ設定を変更することができます。 デフォルトの jvm.options ファイルを直接編集しない限り、自分で設定したものに Elasticsearch のデフォルトの設定が追加されます。 デフォルトの設定を無効化するには、 -Xlog:disable でログを無効にし、その上で独自のコマンドラインオプションを指定します。 この設定により全ての JVM ログが無効になるので、利用可能なオプションを確認の上、必要なものはすべて有効化してください。\nJEP に含まれていないその他のオプションについては、 Enable Logging with the JVM Unified Logging Framework を参照してください。\n例     GC ログの出力先を /opt/my-app/gc.log 他、いくつかサンプルでオプションを指定 $ES_HOME/config/jvm.options.d/gc.options に作成  1 2 3 4 5 6 7 8  # デフォルトの設定をすべて無効化 -Xlog:disable # `uptime` の代わりに `utctime` を指定している以外、 JEP 158 のデフォルトの設定のとおり -Xlog:all=warning:stderr:utctime,level,tags # GC ログの出力先の変更、他 -Xlog:gc*,gc+age=trace,safepoint:file=/opt/my-app/gc.log:utctime,pid,tags:filecount=32,filesize=64m   Docker 版 ES にて GC のデバッグログを標準エラー (stderr) に変更する例です。 コンテナのオーケストレーターにその後のログの処理を移譲します。 環境変数 ES_JAVA_OPTS に指定します。\n1 2  MY_OPTS=\u0026#34;-Xlog:disable -Xlog:all=warning:stderr:utctime,level,tags -Xlog:gc=debug:stderr:utctime\u0026#34; docker run -e ES_JAVA_OPTS=\u0026#34;$MY_OPTS\u0026#34; # etc   tmp ファイルの設定    デフォルトでは、 Elasticsearch の起動スクリプトがシステムの tmp ディレクトリ直下に専用のtmp ファイル用のディレクリトリを生成します。\n一部の Linux ディストリビューションは、最近アクセスされていない tmp ファイルを、システムのユーティリティが /tmp からファイルやディレクトリを削除します。 Elasticsearch による tmp ディレクトリを必要とする機能が長時間使用されなかった場合、 Elasticsearch の実行中に tmp ディレクトリが削除されてしまう可能性があり、 その結果問題が発生する場合があります。\n.deb または .rpm パッケージを用いて Elasticsearch をインストールし systemd で実行する場合、 Elasticsearch が使用する tmp ディレクトリは 定期的な /tmp 配下の削除の対象から除外されます。\nLinux や MacOS に tar.gz 形式のものをインストールし長期間運用する場合は、 Elasticsearch 専用の tmp ディレクトリを作成することを検討してください。 このディレクトリは Elasticsearch を起動するユーザのみがアクセス可能になるようパーミッションを設定する必要があります。 そして、 Elasticsearch を起動する前に、環境変数 $ES_TMPDIR にそのパスを指定してください。\nJVM fatal error ログ    Fatal error log のログ出力先のデフォルトは path.logs になります。 RPM や Debian 系では /var/log/elasticsearch 、 Linux や MacOS 、 Windows の場合は $ES_ROOT/logs になります。\nこのログは、 JVM にて segmentation fault などの致命的なエラーが発生した場合に生成されます。 jvm.options の -XX:ErrorFile=... で変更可能です。\nクラスタのバックアップ    Snapshots を作成することで、データの損失を防ぐことができます。 Snapshot lifecycle management を用いることで、かんたんに定期的にクラスタの snapshot を作成できます。\n詳細は Back up a cluster を参照してください。\n 注意\nSnapshot の作成以外の方法でバックアップを取ることはできません。\nノードの path.data ディレクトリをコピーして Elasticsearch クラスタのバックアップを取ることはできません。 ファイルシステムレベルのバックアップからデータを復元する方法はサポートされていません。 このようなバックアップからクラスタをリストアしようとすると、ファイルの破損や欠落、その他データの不整合が発生してクラスタの起動に失敗したり、 データの一部が静かに失われた上でクラスタの起動に成功したように見える可能性があります。\n "},{"id":5,"href":"/study-elasticsearch-with-ktor/elasticsearch/setup/configure/","title":"設定","parent":"構築","content":"参照元ドキュメント : Configuring Elasticsearch\nElasticsearch はだいたいデフォルトの設定値で動きます。 Cluster update settings を使用して起動中のクラスタのほとんどの設定を変更できます。\n設定ファイルには、ノード固有の設定 (node.name や path など) や、ノードがクラスタに参加するための設定 (cluster.name や network.host など) を含める必要があります。\n設定ファイル群の場所    Elasticsearch は3つの設定ファイルを持ちます。\n   設定ファイル名 役割     elasticsearch.yml Elasticsearch の設定   jvm.options Elasticsearch が起動する JVM の設定   log4j2.properties Elasticsearch のログにまつわる設定    これらのファイルは config ディレクトリに配置する必要があります。 config ディレクトリの場所は、アーカイブ (tar.gz や zip) を用いてインストールしたか、パッケージ (deb や rpm など)　インストールしたかによって変わります。\nアーカイブを用いてインストールした場合 (tar.gz, zip, \u0026hellip;\u0026hellip;)    config ディレクトリのデフォルトの場所は $ES_HOME/config になります。 環境変数 ES_PATH_CONF を用いて config ディレクトリの場所を変更することができます。\n1  ES_PATH_CONF=\u0026#34;/path/to/my/config\u0026#34; \u0026#34;${ES_HOME}/bin/elasticsearch\u0026#34;   上記では実行時に ES_PATH_CONF を指定しましたが、コマンドラインや shell script などを介して export しても構いません。\nパッケージインストールの場合 (deb, rpm, \u0026hellip;\u0026hellip;)    config ディレクトリのデフォルトの場所は /etc/elasticsearch になります。 環境変数 ES_PATH_CONF を用いて config ディレクトリの場所を変更することができますが、 shell でこれを設定しても不十分です。\n代わりに、この変数は /etc/default/elasticsearch (Debian 系) および /etc/sysconfig/elasticsearch (RHEL 系) を参照します。 config ディレクトリの場所を変更するためには、これらのいずれかで ES_PATH_CONF=/etc/elasticsearch の行を適宜変更する必要があります。\n設定ファイルの構成    設定ファイルは YAML 形式です。 例として data ディレクトリと logs ディレクトリのパスを指定します。\n1 2 3  path:data:/var/lib/elasticsearchlogs:/var/log/elasticsearch  設定は以下のように平坦化しても構いません。\n1 2  path.data:/var/lib/elasticsearchpath.logs:/var/log/elasticsearch  YAML では、非スカラ値をシーケンスで表現することができます。\n1 2 3 4  discovery.seed_hosts:- 192.168.1.10:9300- 192.168.1.11- seeds.mydomain.com  あまり一般的ではありませんが、非スカラ値は配列でも表現できます。\n1  discovery.seed_hosts:[\u0026#34;192.168.1.10:9300\u0026#34;,\u0026#34;192.168.1.11\u0026#34;,\u0026#34;seeds.mydomain.com\u0026#34;]  環境変数の展開    環境変数は ${...} 記法を用いることで参照および展開が可能です。\n1 2  node.name:${HOSTNAME}network.host:${ES_NETWORK_HOST}  環境変数の値は単純な文字列でなければなりません。 Elasticsearch にリストとして解析させるためには、カンマ区切りの文字列で指定します。\n1  export HOSTNAME=\u0026#34;host1,host2\u0026#34;   クラスタのノードの設定    クラスタやノードの設定はも動的にも静的にも指定可能です。\n動的    Cluster update settings API を用いることで、実行中のクラスタに対し、、動的に設定を変更することができます。 elasticsearch.yml を使用して、起動していないまたはシャットダウンしたノード上で動的な設定をローカルに構成することもできます。\nCluster update settings API による更新は、永続化されるものと、再起動時にリセットされる一時的なものがあります。 また、 API にて null 値を指定することで、設定をリセットすることができます。\n複数の方法で同じ項目を設定した場合、 Elasticsearch は以下の優先度で設定を適用します。\n 一過性の設定 (transient setting) 永続的な設定 (persistent setting) elasticsearch.yml による設定 デフォルト値  例えば、一過性の設定を行うことで、永続化した設定や elasticsearch.yml による設定を上書きすることができます。\n Note.\nCluster update settings API は動的なクラスタ全体の設定を行い、 elasticsearch.yml はローカルな設定のみを行うことを推奨します。\nCluster update settings API を使用することで、全てのノードで同じ設定を行う事ができます。 誤って期待していないノードの elasticsearch.yml を変更してしまうと、設定の矛盾に気づくのが難しくなります。\n 静的    静的な設定は起動前またはシャットダウン済のノードに対してのみ elasticsearch.yml にて変更可能です。\n静的な設定は、クラスタ内のすべてのノードで設定を行う必要があります。\n"},{"id":6,"href":"/study-elasticsearch-with-ktor/elasticsearch/setup/install/docker/","title":"Docker","parent":"インストール","content":"参照元ドキュメント : Install Elasticsearch with Docker\ncentos:8 ベースの Docker イメージがあります。\nイメージは www.docker.elastic.co で配布されています。 ソースコードは Github にあります。\nDocker image の pull    Elastic Docker レジストリから pull するだけです。\n1  docker pull docker.elastic.co/elasticsearch/elasticsearch:7.13.1   Docker を用いて単一ノードクラスタで起動する    開発やテストのためにシングルノードの Elasticsearch クラスタを起動するには、 single-node discovery を指定して bootstrap checks をスキップします。\n1  docker run -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; docker.elastic.co/elasticsearch/elasticsearch:7.13.1   Docker Compose を利用して複数ノードのクラスタを起動する    Docker Compose を利用して、例として 3-node の Elasticsearch クラスタを起動します。\n docker-compose.yml を作成 docker-compose.yml (click to fold/expand) ↕  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70  version:\u0026#39;2.2\u0026#39;services:es01:image:docker.elastic.co/elasticsearch/elasticsearch:7.13.1container_name:es01environment:- node.name=es01- cluster.name=es-docker-cluster- discovery.seed_hosts=es02,es03- cluster.initial_master_nodes=es01,es02,es03- bootstrap.memory_lock=true- \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34;ulimits:memlock:soft:-1hard:-1volumes:- data01:/usr/share/elasticsearch/dataports:- 9200:9200networks:- elastices02:image:docker.elastic.co/elasticsearch/elasticsearch:7.13.1container_name:es02environment:- node.name=es02- cluster.name=es-docker-cluster- discovery.seed_hosts=es01,es03- cluster.initial_master_nodes=es01,es02,es03- bootstrap.memory_lock=true- \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34;ulimits:memlock:soft:-1hard:-1volumes:- data02:/usr/share/elasticsearch/datanetworks:- elastices03:image:docker.elastic.co/elasticsearch/elasticsearch:7.13.1container_name:es03environment:- node.name=es03- cluster.name=es-docker-cluster- discovery.seed_hosts=es01,es02- cluster.initial_master_nodes=es01,es02,es03- bootstrap.memory_lock=true- \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34;ulimits:memlock:soft:-1hard:-1volumes:- data03:/usr/share/elasticsearch/datanetworks:- elasticvolumes:data01:driver:localdata02:driver:localdata03:driver:localnetworks:elastic:driver:bridge      es01 は localhost:9200 を listen し、 es02 と es03 は Docker network 上で es01 とやりとりする   docker-compose でクラスタを起動する 1  docker compose up    _cat/nodes にリクエストを投げて、ノード群が正しく起動していることを確認する 1  curl -X GET \u0026#34;localhost:9200/_cat/nodes?v=true\u0026amp;pretty\u0026#34;     ログメッセージはコンソールに送られ、設定された Docker ログドライバによって処理されます。 デフォルトでは、 docker logs でログを確認可能です。\nElasticsearch コンテナのログを永続化するようにしたい場合は、環境変数 ES_LOG_STYLE に file を指定してください。 これにより、 Elasticsearch には他の配布形式と同じログ設定が適用されます。\ndocker compose down を実行することでクラスタを停止できます。 Docker ボリューム内のデータが保持されているため、 docker compose up でクラスタを再起動しても、 index 等のデータは維持されています。\nクラスタ停止と同時にデータのボリュームを削除するには、 -v オプションを指定します。\n1  docker compose down -v    Note.\n上記の docker-compose.yml では、環境変数 ES_JAVA_OPTS にてヒープサイズに 512MB を指定しています。 本番環境では ES_JAVA_OPTS でヒープサイズを指定することは非推奨です。\n詳細は Manually set the heap size を参照してください。\n  注意\nこの設定では、すべてのネットワークインタフェースで 9200 ポートが公開されてしまうことに注意してください。\nLinux 上の iptables を Docker が操作するため、この Elasticsearch は外部に公開されてしまうことを意味し、 またファイアウォールの設定が無視されてしまう可能性があります。\nもし 9200 ポートを公開せずにリバースプロキシを利用したい場合は、 docker-compose.yml の 9200:9200 を 127.0.0.1:9200:9200 に書き換えてください。 これでホストマシン自身からしか Elasticsearch にアクセスできなくなります。\n  Note.\nDocker Engine に少なくとも 4GiB 以上のメモリを割り当てておいてください。\n  Note.\nDocker for Linux には Docker Compose がプリインストールされていません。\nInstall Compose on Linux を確認の上インストールしてください。\n 複数ノードのクラスタで TLS を有効化する    「Elasticsearch Docker Container 内の通信を暗号化する」と 「Docker でTSL を有効化して起動する」 を参照してください。\n本番環境で Docker images を利用する    下記は本番環境で Docker 上で Elasticsearch を運用する際の必須要件と推奨値になります。\n vm.max_map_count は少なくとも 262144 以上に  Linux  vm.max_map_count は /etc/sysctl.conf で定義されている 1  vm.max_map_count=262144    稼働中のシステム上で動的に設定するには下記コマンドを実行する 1  sysctl -w vm.max_map_count=262144      macOS (Docker for Mac)  vm.max_map_count は xhyve 仮想マシンで定義されている  仮想環境のコンソールをアタッチ 1  screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty    sysctl で値を設定 1  sysctl -w vm.max_map_count=262144    Control a d で screen をデタッチ       elasticsearch ユーザが設定ファイル群を読めるようにする  デフォルトでは、 uid:gid が 1000:0 である elasticsearch ユーザがコンテナ内で Elasticsearch を起動する   nofile と nproc の ulimit を増やす  Docker daemon の init system が許容範囲内の値に設定されていることを確認する  デフォルト値の確認 1  docker run --rm centos:8 /bin/bash -c \u0026#39;ulimit -Hn \u0026amp;\u0026amp; ulimit -Sn \u0026amp;\u0026amp; ulimit -Hu \u0026amp;\u0026amp; ulimit -Su\u0026#39;    コンテナ単位で指定する場合は、 docker run 時に下記のオプションを指定する 1  --ulimit nofile=65535:65535        swap を無効化する  bootstrap.memory_lock: true を指定した場合、 Docker Daemon で memolock: true ulimit を指定するか、前述のサンプルにように docker compose ファイルで明示的に定義する必要がある docker run を使用する場合は、下記のオプションを指定する 1  -e \u0026#34;bootstrap.memory_lock=true\u0026#34; --ulimit memlock=-1:-1      公開ポートをランダム化する  イメージでは TCP ポート 9200 および 9300 が公開される ホストごとに1つのコンテナを固定する場合を除き、 --pulish-all で公開ポートをランダム化する   ヒープサイズを設定する  デフォルトでは、ノードの役割とコンテナが利用可能なメモリサイズをもとに、 JVM のヒープサイズを自動的に決定される  ほとんどの実働環境では、このデフォルト値を利用することを推奨する   手動で設定する場合は、 JVM options ファイルを /usr/share/elasticsearch/config/jvm.options.d に配置されるようにする $ES_JAVA_OPTS 環境変数は他のすべての JVM オプションよりも優先されてしまうため、テスト環境以外での利用は非推奨   image のバージョンを固定する  例: docker.elastic.co/elasticsearch/elasticsearch:7.13.1   /usr/share/elasticsearch/data にデータボリュームをマウントする  コンテナが死んでもデータを失わないようにするため Elasticsearch では I/O 速度が重要になるが、 Docker storage drive は I/O の最適化がされていないため Docker volume plugins が利用可能になるため   devicemapper ストレージドライバを利用している場合、デフォルトの loop-lvm モードではなく direct-lvm モードを利用するよう docker-engine を設定する ログを一元化する  別のログドライバを使用してログを一元化する デフォルトの json-file ログドライバは、本番環境での利用に不適    次のステップ    Elasticsearch のテスト環境が整いました。 一方で、本格的な開発や本番環境を構築する前に、いくつか追加の設定が必要になります。\n Elasticsearch の設定を学ぶ 重要な Elasticsearch の設定 重要なシステムの設定  "},{"id":7,"href":"/study-elasticsearch-with-ktor/elasticsearch/setup/install/rpm/","title":"rpm","parent":"インストール","content":"参照元ドキュメント : Install Elasticsearch with RPM\nRPM 版の Elasticsearch は ウェブサイト上から直接ダウンロード するか、 RPM リポジトリから直接取得 できます。 OpenSuSE、SLES、CentOS、Red Hat、Oracle Enterprise といった RPM ベースのシステムにインストールすることができます。\n Note.\nRPM インストールは、 CentOS 5、SLES 11 を始めとした旧バージョンの RPM へのインストールをサポートしていません。 代わりに tar.gz でのインストール を検討してください。\n 最新の安定版の Elasticsearch は Download Elasticsearch にあります。 旧バージョンは こちら にあります。\nGPG Key をインポート    すべてのパッケージに Elasticsearch Signing Key を用いて fingerprint で署名しています。 (PGP key D88E42B4, https://pgp.mit.edu/ から利用可能)\n1  4609 5ACC 8548 582C 1A26 99A9 D27D 666C D88E 42B4   公開鍵のダウンロードは下記コマンドで行います。\n1  rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch   RPM リポジトリからインストール    下記の内容で elasticsearch.repo ファイルを作成します。 RHEL 系では /etc/yum.repos.d/ 配下に、 OpenSuSE 系では /etc/zypp/repos.d/ 配下に作成します。\n1 2 3 4 5 6 7 8  [elasticsearch] name=Elasticsearch repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=0 autorefresh=1 type=rpm-md   リポジトリ利用の準備が整ったので下記コマンドでインストールします。\n CentOS または古い RHEL 系 1  sudo yum install --enablerepo=elasticsearch elasticsearch    Fedora または新しい RHEL 系 1  sudo dnf install --enablerepo=elasticsearch elasticsearch    OpenSUSE 系 1 2 3  sudo zypper modifyrepo --enable elasticsearch \u0026amp;\u0026amp; \\  sudo zypper install elasticsearch; \\  sudo zypper modifyrepo --disable elasticsearch      Note.\n設定したリポジトリは、デフォルトでは無効になっています。 システムの他の部分をアップグレードした際に Elasticsearch も同時にアップグレードされてしまうことを防ぐためです。\nインストールやアップグレード時は、上記のように明示的にリポジトリを有効化することを推奨します。\n 手動で RPM をインストール    下記コマンドで Elasticsearch 7.13.1 をダウンロードして手動でインストールできます。\n1 2 3 4  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.13.1-x86_64.rpm wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.13.1-x86_64.rpm.sha512 shasum -a 512 -c elasticsearch-7.13.1-x86_64.rpm.sha512 ## 1. sudo rpm --install elasticsearch-7.13.1-x86_64.rpm    公開している checksum とダウンロードされた RPM の SHA ハッシュを比較している  elasticsearch-{version}-x86_64.rpm: OK と返却されれば OK     Note.\nsystemd ベースのディストリビューションでは、インストールスクリプトがカーネルのパラメータ (vm.max_map_count など) を設定しようとします。 systemd-sysctl.service ユニットをマスクすることで、これを回避することができます。\n SysV init v.s. systemd    Elasticsearch をインストールしても、起動時に自動起動するようにはなっていません。 自動起動は、使っているシステムが SysV init を使っているか systemd (新しめのディストリビューション) を使っているかで異なります。\n下記コマンドで確認できます。\n1  ps -p 1   SysV init を用いて Elasticsearch を起動する    システム起動時に Elasticsearch を自動的に起動するには chkconfig コマンドを利用します。\n1  sudo chkconfig --add elasticsearch   Elasticsearch の起動と停止は下記コマンドでできます。\n1 2  sudo -i service elasticsearch start sudo -i service elasticsearch stop   なんからの理由で Elasticsearch の起動に失敗した場合、標準出力に理由を出力します。 ログファイルは /var/log/elasticsearch/ にあります。\nsystemd を用いて Elasticsearch を起動する    システム起動時に Elasticsearch を自動的に起動するには chkconfig コマンドを利用します。\n1 2  sudo /bin/systemctl daemon-reload sudo /bin/systemctl enable elasticsearch.service   Elasticsearch の起動と停止は下記コマンドでできます。\n1 2  sudo systemctl start elasticsearch.service sudo systemctl stop elasticsearch.service   上記のコマンドは、 Elasticsearch が正常に起動したかどうかのフィードバックをしません。 ログは /var/log/elasticsearch/ を確認してください。\nElasticsearch のキーストアをパスワードで保護している場合は、ローカルファイルと systemd の環境変数を使って、 systemd が キーストアのパスワードを読めるようにする必要があります。\nこのローカルファイルが存在する場合は安全に保護しておき、 Elasticsearch が正常に起動したらそのファイルを削除してください。\n1 2 3 4  echo \u0026#34;keystore_password\u0026#34; \u0026gt; /path/to/my_pwd_file.tmp chmod 600 /path/to/my_pwd_file.tmp sudo systemctl set-environment ES_KEYSTORE_PASSPHRASE_FILE=/path/to/my_pwd_file.tmp sudo systemctl start elasticsearch.service   デフォルトの設定では、 Elasticsearch サービスは systemd ジャーナルに情報をログ出力しません。 journalctl ログを有効にするためには、 elasticsearch.service ファイルの ExecStart コマンドラインから --quiet オプションを削除してください。\nsystemd のログが有効になると、 journalctl コマンドでログを得られるようになります。\njournal を tail するコマンドは下記です。\n1  sudo journalctl -f   elasticsearch サービスの journal エントリを一覧化するコマンドは下記です。\n1  sudo journalctl --unit elasticsearch   特定の日付時刻以降の elasticsearch サービスの jounal エントリを確認するコマンドは下記です。\n1  sudo journalctl --unit elasticsearch --since \u0026#34;2016-10-30 18:17:16\u0026#34;   他のオプションは man journalctl か https://www.freedesktop.org/software/systemd/man/journalctl.html を確認してください。\nElasticsearch の起動の確認    localhost の 9200 番ポートに HTTP リクエストを送ることで、 Elasticsearch ノードが起動しているか確認できます。\n1  curl -X GET \u0026#34;localhost:9200/?pretty\u0026#34;   下記のようなレスポンスが返却されれば OK です。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  { \u0026#34;name\u0026#34; : \u0026#34;d1c7ea7b50cf\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;docker-cluster\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;Udx0AkrqR8i-TeUcxAQtKQ\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.13.1\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;9a7758028e4ea59bcab41c12004603c5a7dd84a9\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2021-05-28T17:40:59.346932922Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.8.2\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; }   Elasticsearch の設定    /etc/elasticsearch ディレクトリに Elasticsearch のランタイムの設定があります。 パッケージインストールでは、このディレクトリとその中のファイル群の所有権は root:elasticsearch に設定されます。\nsetgid フラグは /etc/elasticsearch ディレクトリにグループパーミッションを適用し、 Elasticsearch が含まれるすべてのファイルと サブディレクトリを読めるようにします。 すべてのファイルとサブディレクトリは root:elasticsearch の所有権を継承します。 elasticsearch-keystore tool などこのディレクトリ配下からコマンドを実行するには、 root:elasticsearch のパーミッションが必要です。\nElasticsearch はデフォルトでは /etc/elasticsearch/elasticsaerch.yml ファイルから設定を読み込みます。 この設定ファイルの書式は Configuring Elasticsearch を確認してください。\nRPM 版には /etc/sysconfig/elasticsearch にシステムの設定ファイルがあります。 このファイルでは、下記のパラメータを設定できます。\n   環境変数 説明 デフォルト値     ES_JAVA_HOME 自前でインストールした Java へのパス (デフォルトでは内包している OpenJDK が利用される) (なし)   MAX_OPTION_FILES ファイルを開ける最大の数 65535   MAX_LOCKED_MEMORY lock (メモリの内容が swap 領域に吐き出されないようにする; mlock) できる最大容量    MAX_MAP_COUNT プロセスが持つことのできるメモリマップ領域の最大数 (※1) 2621144   ES_PATH_CONF 設定ファイル群のディレクトリのパス (※2) `/etc/elasticsearch   ES_JAVA_OPTS 追加したい JVM システムプロパティ    RESTART_ON_UPGRADE パッケージアップグレードの際に再起動するか (※3) false     ※1 MAX_MAP_COUNT\nインデックスストアタイプに mmapfs を使用している場合は、大きい値を設定してください。\n詳しくは linux kernel documentation の max_map_count を参照してください。\n  ※2 ES_PATH_CONF\n下記3ファイルが必ず含まれている必要があります。\n elasticsearch.yml jvm.options log4j2.properties    ※3 RESTART_ON_UPGRADE\nfalse の場合、パッケージを手動でインストールしたあとに、 Elasticsearch インスタンスを再起動する必要があります。\nクラスタ内でのアップグレードにより、シャードの再配置が継続的に行われ、ネットワークトラフィックが増大し、クラスタの応答が悪くなることを防ぐことを目的とした設定です。\n  Note.\nsystemd を利用しているディストリビューションでは、 /etc/sysconfig/elasticsearch ファイルではなく systemd 経由でシステムのリソース利用の制限を設定する必要があります。\n詳しくは Systemd configuration を参照してください。\n RPM でのディレクトリ構成    RPM は設定ファイル、ログ、データを RPM ベースのシステムにおける適切な場所に配置します。\n   種別 説明 デフォルト値 設定     home Elasticsearch のホームディレクトリ /usr/share/elasticsearch $ES_HOME   bin ノード起動のための elasticsearch やプラグインをインストールするための elasticsearch-plugin などのバイナリスクリプト群 /usr/share/elasticsearch/bin    conf elasticsearch.yml を含む設定ファイル群 /etc/elasticsearch ES_PATH_CONF   conf ヒープサイズやファイルディスクリプタを始めとした環境変数 /etc/sysconfig/elasticsearch    data 各 index や node に割り当てられた shard のデータファイルの配置先 /var/lib/elasticsearch path.data   jdk Elaticsearch が起動するためにバンドルされた JDK, /etc/sysconfig/elasticsearch 内の ES_JAVA_HOME で上書き可能 /usr/share/elasticsearch/jdk    logs ログファイル群 /var/log/elasticsearch path.logs   plugins プラグインのファイル群, 各プラグインはこのサブディレクトリ内に配置される /usr/share/elasticsearch/plugins    repo 共有ファイルシステムのリポジトリの場所 (複数指定可能)\nバックアップ / リストアなどで利用 設定なし path.repo    次のステップ    Elasticsearch のテスト環境が整いました。 一方で、本格的な開発や本番環境を構築する前に、いくつか追加の設定が必要になります。\n Elasticsearch の設定を学ぶ 重要な Elasticsearch の設定 重要なシステムの設定  "},{"id":8,"href":"/study-elasticsearch-with-ktor/elasticsearch/setup/install/targz/","title":"tar.gz (Linux, MacOS)","parent":"インストール","content":"参照元ドキュメント : Install Elasticsearch from archive on Linux or MacOS\nLinux および MacOS 向けの tar.gz アーカイブを用いたインストール手順\n最新安定版の Elasticsearch は Download Elasticsearch にあります。 過去のバージョンは Past Releases page にあります。\nElasticsearch は OpenJDK がバンドルされています。 (GPLv2+CE)\n自前の JVM を利用する場合は、 こちら を確認してください。\n for Linux    Elasticsearch v7.13.1 の例です。\n1 2 3 4 5  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.13.1-linux-x86_64.tar.gz wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.13.1-linux-x86_64.tar.gz.sha512 shasum -a 512 -c elasticsearch-7.13.1-linux-x86_64.tar.gz.sha512 # 1. tar -xzf elasticsearch-7.13.1-linux-x86_64.tar.gz cd elasticsearch-7.13.1/ # 2.    elasticsearch-{version}-linux-x86_64.tar.gz: OK と出力されれば ok このディレクトリが $ES_HOME となる  for MacOS    Elasticsearch v7.13.1 の例です。\n1 2 3 4 5  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.13.1-darwin-x86_64.tar.gz wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.13.1-darwin-x86_64.tar.gz.sha512 shasum -a 512 -c elasticsearch-7.13.1-darwin-x86_64.tar.gz.sha512 tar -xzf elasticsearch-7.13.1-darwin-x86_64.tar.gz cd elasticsearch-7.13.1/    elasticsearch-{version}-darwin-x86_64.tar.gz: OK と出力されれば ok このディレクトリが $ES_HOME となる  CLI から Elasitcsearch を起動    1  ./bin/elasticsearch   Elasticsearch に同梱されているスクリプトは、配列をサポートするバージョンの bash (4系以降) を必要とし、 /bin/bash で利用できることを前提としています。  Elasticsearch が起動していることの確認    localhost:9200 に HTTP リクエストを送り、期待通りに返却されることを確認します。\n1  curl -X GET \u0026#34;localhost:9200/?pretty\u0026#34;   Docker 版の例ですが、下記と似たようなレスポンスが返却されれば ok です。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  { \u0026#34;name\u0026#34; : \u0026#34;d1c7ea7b50cf\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;docker-cluster\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;Udx0AkrqR8i-TeUcxAQtKQ\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.13.1\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;9a7758028e4ea59bcab41c12004603c5a7dd84a9\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2021-05-28T17:40:59.346932922Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.8.2\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; }   -q または --quiet をコマンドラインオプションに指定することで、標準出力 (stdout) へのログ出力を無効化できます。\nデーモン起動    Elasticsearch をデーモンとして起動する場合は、 -d オプションをつけます。 -p オプションでプロセスIDをファイルに記録できます。\nログファイルは $ES_HOME/logs/ 配下に配置されます。 Elasticsearch を停止するには、 pid ファイルに記録されているプロセスIDを指定します。\n1  pkill -F pid   .tar.gz パッケージ版の Elasticsearch には systemd モジュールが含まれていません。 Elasticsearch をサービスとして管理する場合は、代わりに Debian または RPM パッケージを利用してください。  コマンドラインから Elasticsearch を設定する    Elasticsearch はデフォルトで $ES_HOME/config/elasticsearch.yml に記載されている設定を読み込みます。 設定ファイルのフォーマットは Configuring Elasticsearch に説明があります。\n設定ファイルで指定できる設定は、 -E オプションを用いることでコマンドラインでも指定できます。\n1  ./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1   Configuring Elasticsearch: {{ relref \u0026ldquo;../configure/_index.md\u0026rdquo; }}\n通常、クラスタ全体の設定 (cluster.name など) は elasticsearch.yml で定義します。 ノード固有の設定 (node.name など) はコマンドラインで指定します。  ディレクトリ構成    配布されている圧縮ファイルは、自己完結型です。 すべてのファイルとディレクトリは、アーカイブを解凍したときに作成されるディレクトリである $ES_HOME に含まれています。\nElasticsearch を使い始めるときは別途ディレクトリ等をつくる必要はなく、アンインストールするときは $ES_HOME を削除するだけで完了します。 ただし、あとで重要なデータを誤って削除してしまわないように、 config ディレクトリ、 data ディレクトリ、 logs ディレクトリをデフォルト以外の場所に変更することをおすすめします。\n   種別 説明 デフォルトの場所 設定名     home Elasticsearch のホームディレクトリ または $ES_HOME アーカイブを解凍した場所 $ES_HOME   bin ノードの起動 (elasticsearch) や\nプラグインのインストール (elasticsearch-plugin) などを\n行うためのバイナリスクリプト群 $ES_HOME/bin    conf elasticsearch.yml を始めとした設定ファイル群 $ES_HOME/config $ES_PATH_CONF   data 各 index やノードに割り当てられた shard データ群 $ES_HOME/data path.data   logs ログファイル群 $ES_HOME/logs path.logs   plugins プラグインファイル群\n(各プラグインはサブディレクトリ配下に配置される) $ES_HOME/plugins    repo 共有ファイルシステムのリポジトリの場所 (複数指定可能)\nバックアップ / リストアなどで利用 設定なし path.repo    次のステップ    Elasticsearch のテスト環境が整いました。 一方で、本格的な開発や本番環境を構築する前に、いくつか追加の設定が必要になります。\n Elasticsearch の設定を学ぶ 重要な Elasticsearch の設定 重要なシステムの設定  "},{"id":9,"href":"/study-elasticsearch-with-ktor/elasticsearch/setup/install/","title":"インストール","parent":"構築","content":"参照元ドキュメント : Installing Elasticsearch\n自前のサーバにインストールする方法と、 SaaS を利用する方法があります。\nSaaS (Hosted Elasticsearch)    マネージドの Elasticsearch と Kibana は、 Amazon Web Service 、 Google Cloud Platform 、 Microsoft Azure で利用可能です。\nElasticsearch Service\n自前サーバにインストール    下記のパッケージフォーマットで提供されいてます。\n   Platform format link     Linux, MacOS tar.gz Install Elasticsearch from archive on Linux or MacOS   Windows zip Install Elasticsearch with .zip on Windows    Debian deb Install Elasticsearch with Debian Package    RHEL rpm Install Elasticsearch with RPM   Windows (beta) msi Install Elasticsearch with Windows MSI Installer    Docker  Install Elasticsearch with Docker   Homebrew  Install Elasticsearch on macOS with Homebrew    Puppet  puppet-elasticsearch    Chef  cookbook-elasticsearch    Ansible  ansible-elasticsearch     "},{"id":10,"href":"/study-elasticsearch-with-ktor/ktor/","title":"Ktor","parent":"Study Elasticsearch with Ktor","content":" Ktor official document (1.6.0) Ktor 日本語ドキュメント (1.4.1)  "},{"id":11,"href":"/study-elasticsearch-with-ktor/elasticsearch/setup/","title":"構築","parent":"Elasticsearch","content":"参照元ドキュメント : Set up Elasticsearch\nこの章には下記に関する情報があります。\n ダウンロード インストール 起動 設定  サポートされているプラットフォーム    OS や JVM に関する推奨環境は こちら に記載されています。 サポート外の環境でも動作する可能性はあります。\nJava (JVM) バージョン    Elasticsearch は Java で開発されており、各ディストリビューションには JDK メンテナから提供されたバンドル版の OpenJDK (GPLv2+CE) が含まれています。 Elasticsearch のホームディレクトリ配下の jdk ディレクトリに推奨 JVM である OpenJDK が配置されています。\n自前でインストールした JVM を利用する場合は、 Java Home のパスを環境変数 ES_JAVA_HOME に指定してください。 その場合、バンドルされている Java の LTS バージョンを使用することを推奨します。 既知の不具合を含む Java バージョンが指定されている場合、 Elasticsearch は起動しません。 自前でインストールした JVM を使用する場合、バンドルされている JVM のディレクトリは削除して ok です。\n"},{"id":12,"href":"/study-elasticsearch-with-ktor/elasticsearch/quickstart/quickstart/","title":"Quick start","parent":"Elasticsearch","content":"参照元ドキュメント : Official Document - Quick start\nQuick start     Elasticsearch をテスト環境にインストールし実行 Elasticsearch にデータを追加 データを検索およびソート 検索時に構造化されていないコンテンツからフィールドを抽出  Step 1. 起動    Elasticsearch     Docker Desktop を起動 下記を実行  1 2 3  docker network create elastic docker pull docker.elastic.co/elasticsearch/elasticsearch:7.13.1 docker run --name es01-test --net elastic -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; docker.elastic.co/elasticsearch/elasticsearch:7.13.1   http://localhost:9200/ へアクセスし、 JSON が返却されれば OK です。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  { \u0026#34;name\u0026#34;: \u0026#34;187e3cc75202\u0026#34;, \u0026#34;cluster_name\u0026#34;: \u0026#34;docker-cluster\u0026#34;, \u0026#34;cluster_uuid\u0026#34;: \u0026#34;tjZJV2qWQtutpBCruoAUCA\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;7.13.1\u0026#34;, \u0026#34;build_flavor\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34;: \u0026#34;5ca8591c6fcdb1260ce95b08a8e023559635c6f3\u0026#34;, \u0026#34;build_date\u0026#34;: \u0026#34;2021-05-19T22:22:26.081971330Z\u0026#34;, \u0026#34;build_snapshot\u0026#34;: false, \u0026#34;lucene_version\u0026#34;: \u0026#34;8.8.2\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34;: \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34;: \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; }   Kibana    直感的な UI で Elasticsearch 内のデータを解析、表示、管理するには Kibana を利用します。\n1 2  docker pull docker.elastic.co/kibana/kibana:7.13.1 docker run --name kib01-test --net elastic -p 5601:5601 -e \u0026#34;ELASTICSEARCH_HOSTS=http://es01-test:9200\u0026#34; docker.elastic.co/kibana/kibana:7.13.1   http://localhost:5601/ へアクセスし、 Kibana の UI が表示されれば OK です。\nStep 2. Eleasticsearch にリクエストを送ってみる    CUrl を用いるか、 Kibana の DevTools \u0026gt; Console からリクエストを送ります。\n1  curl -XGET http://localhost:9200/   Step 3. データを追加    JSON オブジェクト形式のドキュメントと呼ばれるデータを Elasticsearch に追加します。 ログやメトリクスなどの時系列データには、 @timestamp フィールドが必要になります。\n単一のドキュメントの追加    logs-my_app-default index に単一のログを投入します。 logs-my_app-default がない場合、ビルトインの logs-*-* index template を用いて自動的に作成されます。\n1 2 3 4 5 6 7  POST logs-my_app-default/_doc{ \u0026#34;@timestamp\u0026#34;: \u0026#34;2099-05-06T16:21:15.000Z\u0026#34;, \u0026#34;event\u0026#34;: { \u0026#34;original\u0026#34;: \u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34; }}  レスポンスとして、 Elasticsearch が生成したドキュメントのメタデータが返却されます。\n ドキュメントが保持される backing _index  Elasticsearch は backing index の名前を自動的に生成する   インデックス内のドキュメントのユニークな _id  1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;,  \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;8yp6zHkBfubf8FpwI40r\u0026#34;,  \u0026#34;_version\u0026#34; : 1, \u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 2, \u0026#34;successful\u0026#34; : 1, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;_seq_no\u0026#34; : 0, \u0026#34;_primary_term\u0026#34; : 1 }   複数のドキュメントの追加    1リクエストで複数のドキュメントを追加するには、 bulk API を利用します。 バルクデータは NDJSON (newline-delimited JSON) で表現します。 最終行も含め、各行の末尾は改行文字 (\\n) で終わる必要があります。\n1 2 3 4 5  PUT logs-my_app-default/_bulk{ \u0026#34;create\u0026#34;: { } }{ \u0026#34;@timestamp\u0026#34;: \u0026#34;2099-05-07T16:24:32.000Z\u0026#34;, \u0026#34;event\u0026#34;: { \u0026#34;original\u0026#34;: \u0026#34;192.0.2.242 - - [07/May/2020:16:24:32 -0500] \\\u0026#34;GET /images/hm_nbg.jpg HTTP/1.0\\\u0026#34; 304 0\u0026#34; } }{ \u0026#34;create\u0026#34;: { } }{ \u0026#34;@timestamp\u0026#34;: \u0026#34;2099-05-08T16:25:42.000Z\u0026#34;, \u0026#34;event\u0026#34;: { \u0026#34;original\u0026#34;: \u0026#34;192.0.2.255 - - [08/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34; } }  Step 4. 検索    インデックスされたドキュメントは準リアルタイムで検索可能です。 インデックスしたデータストリームを検索するには、 search API を利用します。\n下記は logs-my_app-default 内の前エントリを取得し @timestamp の降順で取得するクエリです。\n1 2 3 4 5 6 7 8 9 10 11  GET logs-my_app-default/_search{ \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: { } }, \u0026#34;sort\u0026#34;: [ { \u0026#34;@timestamp\u0026#34;: \u0026#34;desc\u0026#34; } ]}  デフォルトでは、 hits セクションに検索結果上位10ドキュメントが返却されます。 各 _source には index したオリジナルの JSON オブジェクトが格納されます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  { \u0026#34;took\u0026#34; : 359, \u0026#34;timed_out\u0026#34; : false, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;skipped\u0026#34; : 0, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 3, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; },  \u0026#34;max_score\u0026#34; : null, \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;-Cqg5HkBfubf8FpwzI3A\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;_source\u0026#34; : { \u0026#34;@timestamp\u0026#34; : \u0026#34;2099-05-08T16:25:42.000Z\u0026#34;, \u0026#34;event\u0026#34; : { \u0026#34;original\u0026#34; : \u0026#34;\u0026#34;\u0026#34;192.0.2.255 - - [08/May/2099:16:25:42 +0000] \u0026#34;GET /favicon.ico HTTP/1.0\u0026#34; 200 3638\u0026#34;\u0026#34;\u0026#34; }  }, \u0026#34;sort\u0026#34; : [ 4081940742000 ] }, { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;9yqg5HkBfubf8FpwzI28\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;_source\u0026#34; : { \u0026#34;@timestamp\u0026#34; : \u0026#34;2099-05-07T16:24:32.000Z\u0026#34;, \u0026#34;event\u0026#34; : { \u0026#34;original\u0026#34; : \u0026#34;\u0026#34;\u0026#34;192.0.2.242 - - [07/May/2020:16:24:32 -0500] \u0026#34;GET /images/hm_nbg.jpg HTTP/1.0\u0026#34; 304 0\u0026#34;\u0026#34;\u0026#34; }  }, \u0026#34;sort\u0026#34; : [ 4081854272000 ] }, { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;8yp6zHkBfubf8FpwI40r\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;_source\u0026#34; : { \u0026#34;@timestamp\u0026#34; : \u0026#34;2099-05-06T16:21:15.000Z\u0026#34;, \u0026#34;event\u0026#34; : { \u0026#34;original\u0026#34; : \u0026#34;\u0026#34;\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \u0026#34;GET /images/bg.jpg HTTP/1.0\u0026#34; 200 24736\u0026#34;\u0026#34;\u0026#34; }  }, \u0026#34;sort\u0026#34; : [ 4081767675000 ] } ] } }   特定のフィールドの取得    1ドキュメントのサイズが大きい場合、 _source 全体を解析するのはしんどいです。 レスポンスから source を除外するには、 _source パラメータに false を指定します。 その上で、 fields パラメータにて必要なフィールドを指定します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  GET logs-my_app-default/_search{ \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: { } }, \u0026#34;fields\u0026#34;: [ \u0026#34;@timestamp\u0026#34; ], \u0026#34;_source\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;@timestamp\u0026#34;: \u0026#34;desc\u0026#34; } ]}  レスポンスには、ヒットしたドキュメントのフィールドの値が平坦な配列として含まれます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  { \u0026#34;took\u0026#34; : 134, \u0026#34;timed_out\u0026#34; : false, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;skipped\u0026#34; : 0, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 3, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34; : null, \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;-Cqg5HkBfubf8FpwzI3A\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-08T16:25:42.000Z\u0026#34; ] },  \u0026#34;sort\u0026#34; : [ 4081940742000 ] }, { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;9yqg5HkBfubf8FpwzI28\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-07T16:24:32.000Z\u0026#34; ] },  \u0026#34;sort\u0026#34; : [ 4081854272000 ] }, { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;8yp6zHkBfubf8FpwI40r\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-06T16:21:15.000Z\u0026#34; ] },  \u0026#34;sort\u0026#34; : [ 4081767675000 ] } ] } }   日付範囲での検索    特定の間や IP レンジで検索する場合は、 range クエリを使用します。\n絶対日時指定    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  GET logs-my_app-default/_search{ \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;@timestamp\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2099-05-05\u0026#34;, \u0026#34;lt\u0026#34;: \u0026#34;2099-05-08\u0026#34; } } }, \u0026#34;fields\u0026#34;: [ \u0026#34;@timestamp\u0026#34; ], \u0026#34;_source\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;@timestamp\u0026#34;: \u0026#34;desc\u0026#34; } ]}  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  { \u0026#34;took\u0026#34; : 18, \u0026#34;timed_out\u0026#34; : false, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;skipped\u0026#34; : 0, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 2, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34; : null, \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;9yqg5HkBfubf8FpwzI28\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-07T16:24:32.000Z\u0026#34; ] }, \u0026#34;sort\u0026#34; : [ 4081854272000 ] }, { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;8yp6zHkBfubf8FpwI40r\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-06T16:21:15.000Z\u0026#34; ] }, \u0026#34;sort\u0026#34; : [ 4081767675000 ] } ] } }   相対日時指定    日付関数を用いて相対的な時間範囲を定義できます。 下記のクエリで、過去の日付のデータを検索できます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  GET logs-my_app-default/_search{ \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;@timestamp\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;now-1d/d\u0026#34;, \u0026#34;lt\u0026#34;: \u0026#34;now/d\u0026#34; } } }, \u0026#34;fields\u0026#34;: [ \u0026#34;@timestamp\u0026#34; ], \u0026#34;_source\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;@timestamp\u0026#34;: \u0026#34;desc\u0026#34; } ]}  投入済のログには該当するものがないため、空が返却されます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  { \u0026#34;took\u0026#34; : 9, \u0026#34;timed_out\u0026#34; : false, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;skipped\u0026#34; : 0, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 0, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34; : null, \u0026#34;hits\u0026#34; : [ ] } }   構造化されていない要素からフィードを抽出    検索時に、ログのメッセージなどのような構造化されていない要素から 動的フィールド (Runtime field) を抽出することできます。\nevent.original から動的フィールド source.id を抽出してみます。 レスポンスに含めるには、 fields パラメータにも source.id を指定する必要があります。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  GET logs-my_app-default/_search{ \u0026#34;runtime_mappings\u0026#34;: { \u0026#34;source.ip\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;ip\u0026#34;, \u0026#34;script\u0026#34;: \u0026#34;\u0026#34;\u0026#34; String sourceip = grok(\u0026#39;%{IPORHOST:sourceip} .*\u0026#39;) .extract(doc[\u0026#34;event.original\u0026#34;].value) ?.sourceip; if (sourceip != null) { emit(sourceip); } \u0026#34;\u0026#34;\u0026#34; } }, \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;@timestamp\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2099-05-05\u0026#34;, \u0026#34;lt\u0026#34;: \u0026#34;2099-05-08\u0026#34; } } }, \u0026#34;fields\u0026#34;: [ \u0026#34;@timestamp\u0026#34;, \u0026#34;source.ip\u0026#34; ], \u0026#34;_source\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;@timestamp\u0026#34;: \u0026#34;desc\u0026#34; } ]}  fields.source.ip として返却されます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  { \u0026#34;took\u0026#34; : 14, \u0026#34;timed_out\u0026#34; : false, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;skipped\u0026#34; : 0, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 2, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34; : null, \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;9yqg5HkBfubf8FpwzI28\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-07T16:24:32.000Z\u0026#34; ], \u0026#34;source.ip\u0026#34; : [ \u0026#34;192.0.2.242\u0026#34; ]  }, \u0026#34;sort\u0026#34; : [ 4081854272000 ] }, { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;8yp6zHkBfubf8FpwI40r\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-06T16:21:15.000Z\u0026#34; ], \u0026#34;source.ip\u0026#34; : [ \u0026#34;192.0.2.42\u0026#34; ]  }, \u0026#34;sort\u0026#34; : [ 4081767675000 ] } ] } }   クエリの結合    bool クエリを用いることで、複数のクエリ結合することができます。 下記のクエリは、 @timestamp と動的フィールドsource.ip の2つの range クエリを結合しています。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  GET logs-my_app-default/_search{ \u0026#34;runtime_mappings\u0026#34;: { \u0026#34;source.ip\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;ip\u0026#34;, \u0026#34;script\u0026#34;: \u0026#34;\u0026#34;\u0026#34; String sourceip = grok(\u0026#39;%{IPORHOST:sourceip} .*\u0026#39;) .extract(doc[ \u0026#34;event.original\u0026#34; ].value) ?.sourceip; if (sourceip != null) { emit(sourceip); } \u0026#34;\u0026#34;\u0026#34; } }, \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: [ { \u0026#34;range\u0026#34;: { \u0026#34;@timestamp\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2099-05-05\u0026#34;, \u0026#34;lt\u0026#34;: \u0026#34;2099-05-08\u0026#34; } } }, { \u0026#34;range\u0026#34;: { \u0026#34;source.ip\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;192.0.2.0\u0026#34;, \u0026#34;lte\u0026#34;: \u0026#34;192.0.2.240\u0026#34; } } } ] } }, \u0026#34;fields\u0026#34;: [ \u0026#34;@timestamp\u0026#34;, \u0026#34;source.ip\u0026#34; ], \u0026#34;_source\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;@timestamp\u0026#34;: \u0026#34;desc\u0026#34; } ]}  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  { \u0026#34;took\u0026#34; : 24, \u0026#34;timed_out\u0026#34; : false, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;skipped\u0026#34; : 0, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 1, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34; : null, \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;8yp6zHkBfubf8FpwI40r\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-06T16:21:15.000Z\u0026#34; ], \u0026#34;source.ip\u0026#34; : [ \u0026#34;192.0.2.42\u0026#34; ] }, \u0026#34;sort\u0026#34; : [ 4081767675000 ] } ] } }   データの集約    集約を用いることで、データを要約できます。 (メトリクス、統計、その他解析)\n下記のクエリでは動的フィールド http.response.body.bytes を用いて average_response_size を計算し集約しています。 集約は query でヒットしたドキュメントに対してのみ計算されます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  GET logs-my_app-default/_search{ \u0026#34;runtime_mappings\u0026#34;: { \u0026#34;http.response.body.bytes\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;script\u0026#34;: \u0026#34;\u0026#34;\u0026#34; String bytes = grok(\u0026#39;%{COMMONAPACHELOG}\u0026#39;) .extract(doc[ \u0026#34;event.original\u0026#34; ].value) ?.bytes; if (bytes != null) { emit(Integer.parseInt(bytes)); } \u0026#34;\u0026#34;\u0026#34; } }, \u0026#34;aggs\u0026#34;: { \u0026#34;average_response_size\u0026#34;:{ \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;http.response.body.bytes\u0026#34; } } }, \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: [ { \u0026#34;range\u0026#34;: { \u0026#34;@timestamp\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2099-05-05\u0026#34;, \u0026#34;lt\u0026#34;: \u0026#34;2099-05-08\u0026#34; } } } ] } }, \u0026#34;fields\u0026#34;: [ \u0026#34;@timestamp\u0026#34;, \u0026#34;http.response.body.bytes\u0026#34; ], \u0026#34;_source\u0026#34;: false, \u0026#34;sort\u0026#34;: [ { \u0026#34;@timestamp\u0026#34;: \u0026#34;desc\u0026#34; } ]}  レスポンスの aggregation オブジェクトに、集約結果が格納されます。 2件ヒットしそれぞれの http.response.body.bytes が 0 と 24736 だったため、集約結果 (平均値) は 12368.0 となりました。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  { \u0026#34;took\u0026#34; : 14, \u0026#34;timed_out\u0026#34; : false, \u0026#34;_shards\u0026#34; : { \u0026#34;total\u0026#34; : 1, \u0026#34;successful\u0026#34; : 1, \u0026#34;skipped\u0026#34; : 0, \u0026#34;failed\u0026#34; : 0 }, \u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 2, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34; : null, \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;9yqg5HkBfubf8FpwzI28\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-07T16:24:32.000Z\u0026#34; ], \u0026#34;http.response.body.bytes\u0026#34; : [ 0 ] }, \u0026#34;sort\u0026#34; : [ 4081854272000 ] }, { \u0026#34;_index\u0026#34; : \u0026#34;.ds-logs-my_app-default-2021.06.02-000001\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;8yp6zHkBfubf8FpwI40r\u0026#34;, \u0026#34;_score\u0026#34; : null, \u0026#34;fields\u0026#34; : { \u0026#34;@timestamp\u0026#34; : [ \u0026#34;2099-05-06T16:21:15.000Z\u0026#34; ], \u0026#34;http.response.body.bytes\u0026#34; : [ 24736 ] }, \u0026#34;sort\u0026#34; : [ 4081767675000 ] } ] }, \u0026#34;aggregations\u0026#34; : { \u0026#34;average_response_size\u0026#34; : { \u0026#34;value\u0026#34; : 12368.0 } } }   さらなる検索オプション    他の検索オプションなどは、 共通検索オプション を参照してください。\nStep 5. 後片付け    終わったら、テストデータと index を削除します。\n1  DELETE _data_stream/logs-my_app-default   コンテナの停止、削除、ネットワークの削除     コンテナの停止  1 2  docker stop es01-test docker stop kib01-test   コンテナとネットワークの削除  1 2 3  docker network rm elastic docker rm es01-test docker rm kib01-test   他の話題     データ階層とインデックスライフサイクル管理 (Manage the index lifecycle; ILM) を設定し、時系列データを最大限に活用する  時系列データを Elasticsearch で活用する を参照   Fleet と Elastic Agent を使って、データソースから直接ログやメトリクスを収集し、 Elasticsearch へ送信する  Fleet クイックスタートガイド を参照 (X-Pack 向け)   Kibana を使用して、 Elasticsearch のデータの探索、可視化、管理を行う  Kibana クイックスタートガイド を参照    次    Elasticsearch のセットアップ\n"},{"id":13,"href":"/study-elasticsearch-with-ktor/","title":"Study Elasticsearch with Ktor","parent":"","content":" 注意\n本ページは Elasticsearch と Ktor に関する個人的なメモです。 前提知識が必要であったり不正確な和訳が含まれていたり、情報が古い場合があります。\n最新の正確な情報は公式ドキュメントを参照してください。\n Elasticsearch Ktor   対応バージョン     Elasticsearch 7.13.1 Ktor 1.6.0  "},{"id":14,"href":"/study-elasticsearch-with-ktor/categories/","title":"Categories","parent":"Study Elasticsearch with Ktor","content":""},{"id":15,"href":"/study-elasticsearch-with-ktor/tags/","title":"Tags","parent":"Study Elasticsearch with Ktor","content":""}]